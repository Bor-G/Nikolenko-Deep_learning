{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала импортируем все, что нам понадобится. И загрузим набор данных MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Art\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-6c92a55edaf8>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Art\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Art\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Art\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Art\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Art\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data \n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже обсуждали, датасет состоит из 70 000 размеченных черно-белых изображений, которые разделены между тренировочной, тестовой и валидационной выборками по 55 000,10 000 и 5000 примеров соответственно.   \n",
    "\n",
    "Зададим гиперпараметры сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "latent_space = 128\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте для простоты эксперимента опишем однослойный автокодировщик. Для этого объявим его веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_weights = {\"encoder_w\": tf.Variable(tf.truncated_normal([784, latent_space], stddev=0.1)),\n",
    "              \"encoder_b\": tf.Variable(tf.truncated_normal([latent_space], stddev=0.1)),\n",
    "              \"decoder_w\": tf.Variable(tf.truncated_normal([latent_space, 784], stddev=0.1)), \n",
    "              \"decoder_b\": tf.Variable(tf.truncated_normal([784], stddev=0.1))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И зададим тензоры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_input = tf.placeholder(tf.float32, [batch_size, 784])\n",
    "hidden = tf.nn.sigmoid(tf.matmul(ae_input, ae_weights[\"encoder_w\"]) + ae_weights[\"encoder_b\"])\n",
    "visible_logits = tf.matmul(hidden, ae_weights[\"decoder_w\"]) + ae_weights[\"decoder_b\"]\n",
    "visible = tf.nn.sigmoid(visible_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле тензор visible для обучения не нужен, так как мы будем использовать стандартную функцию ошибки из библиотеки TensorFlow, sigmoid_cross_entropy_with_logits. Однако позже он пригодится нам для того, чтобы визуализировать восстановленные изображения. А сама функция ошибки для\n",
    "автокодировщика в виде перекрестной энтропии запишется так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_cost = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=visible_logits, labels=ae_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем алгоритм оптимизации из TensorFlow, в данном случае AdaGrad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate)\n",
    "ae_op = optimizer.minimize(ae_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и раньше, нам остается только инициализировать переменные, создать сессию и запустить процесс обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(10000):\n",
    "    x_batch, _ = mnist.train.next_batch(batch_size)\n",
    "    sess.run(ae_op, feed_dict={ae_input: x_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения на 10000 мини-батчей ошибка восстановления на тестовых данных составляет примерно 0,22, а после 100000 падает до 0,12 и при дальнейшем обучении может быть улучшена до значений, меньших чем 0,1. Изображения, которые получаются после восстановления, все еще выглядят как цифры, но очень сильно «размыты».   \n",
    "\n",
    "Чтобы сделать разреженный автокодировщик, нужно, как мы обсуждали выше, добавить регуляризатор. Зададим в качестве дополнительных параметров rho и beta вес регуляризации в функции стоимости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.05\n",
    "beta = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим теперь тензор для регуляризационного слагаемого:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rho = tf.reduce_mean(hidden, 0)\n",
    "reg_cost = - tf.reduce_mean(tf.log(data_rho/rho) * rho + tf.log((1-data_rho)/(1-rho)) * (1-rho))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь для оценки p^ мы используем среднее значение активации скрытого слоя по мини-батчу для каждого нейрона, а для упрощения вычислений переворачиваем дроби внутри логарифмов. Общая функция стоимости теперь выглядит так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost = ae_cost + beta * reg_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И именно она передается оптимизатору вместо ae_cost.   \n",
    "\n",
    "Посмотрите внимательно, что здесь произошло: мы задали дополнительное слагаемое для функции ошибки; оно тем меньше, чем ближе распределение активации нейронов к придуманному нами распределению, в котором монетка выпадает орлом (то есть нейрон активируется) с вероятностью р = 0.05. Иными словами,\n",
    "мы просто попросили модель обучиться так, чтобы на каждом отдельном входе на скрытом слое активировалось примерно 5 % нейронов; а параметр beta отвечает за то, насколько убедительно мы ее об этом попросили.   \n",
    "\n",
    "После нескольких миллионов мини-батчей и нескольких эпох обучения модели средние значения нейронов скрытого слоя уменьшатся и станут близки к р."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но где же обещанная разреженность? Ведь хоть значения активаций и уменьшились, они все так же остаются ненулевыми, а нам для улучшения эффективности модели неинтересно иметь околонулевые веса, нам нужны строгие, «жесткие» нули. Давайте проведем небольшой эксперимент: возьмем случайный мини-батч, спроецируем его в вектор активаций скрытого слоя и обнулим все элементы, меньшие 0,1. Поскольку в наших экспериментах р = 0,05, это весьма значительная часть элементов скрытого слоя. Это само по себе вполне ожидаемо, но самое интересное здесь то, что оставшихся элементов будет вполне достаточно для восстановления исходных изображений! Разреженный автокодировщик не обманул: мы действительно обучили скрытый слой так, что теперь можно обнулить все маленькие веса и все еще получить хорошее приближение к данным.   \n",
    "\n",
    "Чтобы это нарисовать, введем дополнительный «зашумленный скрытый слой» и его декодировщик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noised_hidden = tf.nn.relu(hidden - 0.1) + 0.1\n",
    "noised_visible = tf.nn.sigmoid(\n",
    "    tf.matmul(noised_hidden, ae_weights[\"decoder_w\"]) + ae_weights[\"decoder_b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы реализовать шумоподавляющий автокодировщик и протестировать его на MNIST, достаточно внести минимальные изменения в уже написанный код. Начнем с того, что добавим еще одну заглушку для «испорченных» данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_input = tf.placeholder(tf.float32, [batch_size, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, эта заглушка должна иметь такой же размер, как и ae_input, так как функция потерь после сжатия и восстановления примеров будет подсчитываться на основе исходных данных, а не зашумленных. Скрытый слой теперь тоже формируется с использованием новой заглушки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.nn.sigmoid(tf.matmul(noisy_input, ae_weights[\"encoder_w\"]) + ae_weights[\"encoder_b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А когда нам нужно будет для тестирования полученного автокодировщика прогнать через скрытый слой «чистые» данные, без шума, мы просто передадим исходный батч в noisy_input. Основной цикл обучения меняется незначительно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_prob = 0.3\n",
    "updates = 10000\n",
    "\n",
    "for i in range(updates):\n",
    "    x_batch, _ = mnist.train.next_batch(batch_size)\n",
    "    noise_mask = np.random.uniform(0., 1., [batch_size, 784]) < noise_prob\n",
    "    noisy_batch = x_batch.copy()\n",
    "    noisy_batch[noise_mask] = 0.0\n",
    "    sess.run(ae_op, feed_dict={ae_input: x_batch, noisy_input: noisy_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция np.random.uniform возвращает массив со значениями, выбранными (сэмплированными) из случайной величины, равномерно распределенной на отрезке, который задается первыми двумя параметрами; в нашем случае это отрезок [0,1]. Третий параметр задает размер массива. Обратите внимание на то, что перед\n",
    "обнулением элементов входных данных мы копируем батч целиком, вызывая x_batch.copy(); если бы мы этого не сделали, а использовали обычное присваивание, то в результате обнулились бы значения и в x_batch. Для эксперимента мы выбрали вероятность «выкидывания» пиксела noise_prob = 0.3. Эта вероятность на первый взгляд кажется очень большой: как так, мы выкидываем 30 % картинки? Да что там вообще останется? Оказывается, что на практике наилучшие результаты получаются как раз в случаях, когда уровень шума очень, на первый взгляд чрезмерно, большой: просить модель угадывать «закрытую» треть, а то и половину картинки оказывается правильной стратегией."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
