{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продемонстрируем, как свертки работают на практике, на численном примере в TensorFlow. Начнем, как обычно, с импортирования TensorFlow и numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Art\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы никакую модель обучать не планируем, в качестве переменных будет достаточно определить «заглушки» заданного размера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = tf.placeholder(tf.float32, [5, 5])\n",
    "w_inp = tf.placeholder(tf.float32, [3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, операция свертки в TensorFlow оперирует четырехмерными тензорами, а не обычными матрицами, поэтому входные данные нужно привести к соответствующим размерностям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(x_inp, [1, 5, 5, 1])\n",
    "w = tf.reshape(w_inp, [3, 3, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним, что первая размерность тензора х обозначает количество изображений в мини-батче, а последняя — число каналов изображения. Так как мы всего лишь хотим проиллюстрировать описанную выше теорию, нам будет достаточно одной черно-белой картинки. Теперь можно задавать саму операцию свертки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "x_same = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "x_valid_half= tf.nn.conv2d(x, w, strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "x_same_half= tf.nn.conv2d(x, w, strides=[1, 2, 2, 1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аргумент strides задает шаг по изображению. Обратите внимание, что параметр strides просто определяет, как часто мы применяем фильтры по каждой размерности входного тензора, а размерностей этих у него в данном случае четыре. Поэтому, например, первая компонента strides соответствует\n",
    "разным примерам в мини-батче, и если бы она была не равна единице, мы бы просто пропускали часть входных примеров. В данном случае это выглядит странно, и для функции tf.nn.conv2d вряд ли есть смысл задавать strides с неединичной первой компонентой (или пропускать часть цветовых фильтров в четвертой компоненте), но аргумент strides в TensorFlow является более общим и может быть применен к любому тензору, отсюда и «лишние» размерности.  \n",
    "\n",
    "В нашем примере, меняя параметр strides, мы будем просто получать некоторые подматрицы тех матриц, которые мы вычисляли выше. Например, для strides = [l, 2, 2, 1] мы будем пропускать каждую вторую размерность и по строкам, и по столбцам.  \n",
    "\n",
    "Итак, наша «модель» задана. Запишем входные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0, 1, 2, 1, 0],\n",
    "             [4, 1, 0, 1, 0],\n",
    "             [2, 0, 1, 1, 1],\n",
    "             [1, 2, 3, 1, 0],\n",
    "             [0, 4, 3, 2, 0]])\n",
    "w = np.array([[0, 1, 0],\n",
    "             [1, 0, 1],\n",
    "             [2, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось только объявить сессию и вычислить результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "y_valid, y_same, y_valid_half, y_same_half = sess.run(\n",
    "    [x_valid, x_same, x_valid_half, x_same_half],\n",
    "    feed_dict={x_inp: x, w_inp: w}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте для проверки выведем то, что у нас получилось; поскольку на выходе у нас по-прежнему будут получаться четырехмерные тензоры, а мы хотели бы увидеть обыкновенные матрицы, некоторые (тривиальные) размерности мы зафиксируем нулями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding=VALID:\n",
      " [[ 9.  5.  4.]\n",
      " [ 8.  8. 10.]\n",
      " [ 8. 15. 12.]]\n",
      "padding=SAME:\n",
      " [[ 5. 11.  4.  3.  3.]\n",
      " [ 3.  9.  5.  4.  4.]\n",
      " [ 5.  8.  8. 10.  3.]\n",
      " [ 4.  8. 15. 12.  6.]\n",
      " [ 5.  5.  9.  4.  2.]]\n",
      "padding=VALID, stride 2:\n",
      " [[ 9.  4.]\n",
      " [ 8. 12.]]\n",
      "padding=SAME, stride 2:\n",
      " [[5. 4. 3.]\n",
      " [5. 8. 3.]\n",
      " [5. 9. 2.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"padding=VALID:\\n\", y_valid[0, :, :, 0])\n",
    "print(\"padding=SAME:\\n\", y_same[0, :, :, 0])\n",
    "print(\"padding=VALID, stride 2:\\n\", y_valid_half[0, :, :, 0])\n",
    "print(\"padding=SAME, stride 2:\\n\", y_same_half[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы научились делать операцию свертки. После нее можно, как мы уже говорили, применить ту или иную нелинейную функцию h: она будет просто применяться к каждому элементу полученного тензора по отдельности. Но это еще не все. В классическом сверточном слое, кроме линейной свертки и следующей за ней нелинейности, есть и еще одна операция: субдискретизация (pooling; по-русски ее иногда называют еще операцией «подвыборки», от альтернативного английского термина subsampling).  \n",
    "\n",
    "Смысл субдискретизации прост: в сверточных сетях обычно исходят из предположения, что наличие или отсутствие того или иного признака гораздо важнее, чем его точные координаты. Например, при распознавании лиц сверточной сетью нам гораздо важнее понять, есть ли на фотографии лицо и чье, чем узнать, с какого конкретно пиксела оно начинается и в каком заканчивается. Поэтому можно позволить себе «обобщить» выделяемые признаки, потеряв часть информации об их местоположении, но зато сократив размерность.  \n",
    "\n",
    "Обычно в качестве операции субдискретизации к каждой локальной группе нейронов применяется операция взятия максимума (max-pooling).  \n",
    "\n",
    "Хотя в результате субдискретизации действительно теряется часть информации, сеть становится более устойчивой к небольшим трансформациям изображения вроде сдвига или поворота.  \n",
    "\n",
    "Чтобы сделать все это в TensorFlow, как и в случае с операцией свертки, сначала зададим заглушку для входного «изображения» и приведем ее к нужной размерности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = tf.placeholder(tf.float32, [4, 4])\n",
    "x = tf.reshape(x_inp, [1, 4, 4, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно определять операции субдискретизации с помощью специальной функции tf.nn.max_pool; мы попробуем размеры шага 1 и 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "x_valid_half = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что здесь появился не только аргумент strides, который мы уже обсуждали, но и отдельно задаваемый размер окна ksize. Он тоже представляет собой четырехмерный тензор, то есть субдискретизацию можно проводить по любым размерностям, включая элементы мини-батчей и каналы. Это может опять показаться несколько странным; например, что может означать субдискретизация по каналам? Предположим, что перед нами стоит задача проверить, есть ли на данной фотографии попугай особого RGB-семейства, представители которого бывают только монохромными: идеального красного, зеленого или синего цвета. В таком случае мы можем решить, что есть смысл использовать субдискретизацию не только на пространственных измерениях, но и на каналах изображения, например для того, чтобы нейронная сеть могла как можно раньше избавиться от заведомо нерелевантных цветовых каналов. Звучит странно, но давайте попробуем теперь предположить, что на входе не отдельные фотографии, а видео в виде последовательных кадров. Тогда субдискретизация по каналам (если кадры соответствуют каналам) или мини-батчам (если входным примерам) внезапно становится очень осмысленной: соседние кадры почти всегда очень похожи, и если наша цель — распознать присутствие каких-то объектов в видео, то большую часть кадров можно спокойно выбросить.  \n",
    "\n",
    "Доведем наш эксперимент до конца. Для этого объявим входную матрицу, произведем вычисления и выпишем результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0, 1, 2, 1],\n",
    "             [4, 1, 0, 1],\n",
    "             [2, 0, 1, 1],\n",
    "             [1, 2, 3, 1]])\n",
    "\n",
    "y_valid, y_valid_half = sess.run(\n",
    "    [x_valid, x_valid_half],\n",
    "    feed_dict={x_inp: x}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding=VALID:\n",
      " [[4. 2. 2.]\n",
      " [4. 1. 1.]\n",
      " [2. 3. 3.]]\n",
      "padding=VALID, stride 2:\n",
      " [[4. 2.]\n",
      " [2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"padding=VALID:\\n\", y_valid[0, :, :, 0])\n",
    "print(\"padding=VALID, stride 2:\\n\", y_valid_half[0, :, :, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
